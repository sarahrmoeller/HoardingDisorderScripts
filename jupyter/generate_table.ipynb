{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = {\n",
    "    'Incomplete Thought',\n",
    "    'Self Correction',\n",
    "    'Clarification',\n",
    "    'Generic Disfluency',\n",
    "    'Misspeak',\n",
    "    'Unclear',\n",
    "    'Overlap'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "project = \"HD_set1_1-7\"\n",
    "review_dir = f\"../data/{project}/REVIEW/\"\n",
    "# Get all .json files in REVIEW dir\n",
    "json_files = [f for f in os.listdir(review_dir) if os.path.splitext(f)[1] == '.json']\n",
    "test_file = json_files[0]\n",
    "hoarder_flag = int(test_file[0] == '0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'version': '1',\n",
       " 'data': {'project': {'id': 'NDE5MzE1ZWM',\n",
       "   'name': 'HD_set1_1-7',\n",
       "   'completedAt': '2025-02-26T00:50:59.000Z'},\n",
       "  'document': {'id': 'f50c25c9-451a-4693-aea5-28081dac0250',\n",
       "   'name': '001_006.txt'},\n",
       "  'kinds': ['TOKEN_BASED'],\n",
       "  'rows': [[{'content': 'Interviewer:\\r',\n",
       "     'tokens': ['Interviewer:'],\n",
       "     'metadata': []}],\n",
       "   [{'content': \"Yeah. Okay. So the next story, I'm going to read you another story. Here we go. John Doe has several boxes that he keeps in case he needs to store something or decides to move. When the items are delivered to his house he keeps the container the item came in. He is worried that he might get rid of a box that he will need later. Stacks of boxes occupy every room. Before entering his bathroom he must remove several stacks of boxes. His house is extremely cluttered and it's difficult for him to walk in his house. Often, it's difficult for Mr. Doe to find his car keys and wallet, so he'll spend 30 minutes to an hour looking for them until he eventually finds them or forgets what he was looking for. He is almost always late in getting where he needs to be and sometimes does not show up at all. So in your opinion does this person have ...\\r\",\n",
       "     'tokens': ['Yeah.',\n",
       "      'Okay.',\n",
       "      'So',\n",
       "      'the',\n",
       "      'next',\n",
       "      'story,',\n",
       "      \"I'm\",\n",
       "      'going',\n",
       "      'to',\n",
       "      'read',\n",
       "      'you',\n",
       "      'another',\n",
       "      'story.',\n",
       "      'Here',\n",
       "      'we',\n",
       "      'go.',\n",
       "      'John',\n",
       "      'Doe',\n",
       "      'has',\n",
       "      'several',\n",
       "      'boxes',\n",
       "      'that',\n",
       "      'he',\n",
       "      'keeps',\n",
       "      'in',\n",
       "      'case',\n",
       "      'he',\n",
       "      'needs',\n",
       "      'to',\n",
       "      'store',\n",
       "      'something',\n",
       "      'or',\n",
       "      'decides',\n",
       "      'to',\n",
       "      'move.',\n",
       "      'When',\n",
       "      'the',\n",
       "      'items',\n",
       "      'are',\n",
       "      'delivered',\n",
       "      'to',\n",
       "      'his',\n",
       "      'house',\n",
       "      'he',\n",
       "      'keeps',\n",
       "      'the',\n",
       "      'container',\n",
       "      'the',\n",
       "      'item',\n",
       "      'came',\n",
       "      'in.',\n",
       "      'He',\n",
       "      'is',\n",
       "      'worried',\n",
       "      'that',\n",
       "      'he',\n",
       "      'might',\n",
       "      'get',\n",
       "      'rid',\n",
       "      'of',\n",
       "      'a',\n",
       "      'box',\n",
       "      'that',\n",
       "      'he',\n",
       "      'will',\n",
       "      'need',\n",
       "      'later.',\n",
       "      'Stacks',\n",
       "      'of',\n",
       "      'boxes',\n",
       "      'occupy',\n",
       "      'every',\n",
       "      'room.',\n",
       "      'Before',\n",
       "      'entering',\n",
       "      'his',\n",
       "      'bathroom',\n",
       "      'he',\n",
       "      'must',\n",
       "      'remove',\n",
       "      'several',\n",
       "      'stacks',\n",
       "      'of',\n",
       "      'boxes.',\n",
       "      'His',\n",
       "      'house',\n",
       "      'is',\n",
       "      'extremely',\n",
       "      'cluttered',\n",
       "      'and',\n",
       "      \"it's\",\n",
       "      'difficult',\n",
       "      'for',\n",
       "      'him',\n",
       "      'to',\n",
       "      'walk',\n",
       "      'in',\n",
       "      'his',\n",
       "      'house.',\n",
       "      'Often,',\n",
       "      \"it's\",\n",
       "      'difficult',\n",
       "      'for',\n",
       "      'Mr.',\n",
       "      'Doe',\n",
       "      'to',\n",
       "      'find',\n",
       "      'his',\n",
       "      'car',\n",
       "      'keys',\n",
       "      'and',\n",
       "      'wallet,',\n",
       "      'so',\n",
       "      \"he'll\",\n",
       "      'spend',\n",
       "      '30',\n",
       "      'minutes',\n",
       "      'to',\n",
       "      'an',\n",
       "      'hour',\n",
       "      'looking',\n",
       "      'for',\n",
       "      'them',\n",
       "      'until',\n",
       "      'he',\n",
       "      'eventually',\n",
       "      'finds',\n",
       "      'them',\n",
       "      'or',\n",
       "      'forgets',\n",
       "      'what',\n",
       "      'he',\n",
       "      'was',\n",
       "      'looking',\n",
       "      'for.',\n",
       "      'He',\n",
       "      'is',\n",
       "      'almost',\n",
       "      'always',\n",
       "      'late',\n",
       "      'in',\n",
       "      'getting',\n",
       "      'where',\n",
       "      'he',\n",
       "      'needs',\n",
       "      'to',\n",
       "      'be',\n",
       "      'and',\n",
       "      'sometimes',\n",
       "      'does',\n",
       "      'not',\n",
       "      'show',\n",
       "      'up',\n",
       "      'at',\n",
       "      'all.',\n",
       "      'So',\n",
       "      'in',\n",
       "      'your',\n",
       "      'opinion',\n",
       "      'does',\n",
       "      'this',\n",
       "      'person',\n",
       "      'have',\n",
       "      '...'],\n",
       "     'metadata': []}],\n",
       "   [{'content': 'Participant 1:\\r',\n",
       "     'tokens': ['Participant', '1:'],\n",
       "     'metadata': []}],\n",
       "   [{'content': \"No. Yes, he's a clutter. He's a terrible clutter and that's not me.\\r\",\n",
       "     'tokens': ['No.',\n",
       "      'Yes,',\n",
       "      \"he's\",\n",
       "      'a',\n",
       "      'clutter.',\n",
       "      \"He's\",\n",
       "      'a',\n",
       "      'terrible',\n",
       "      'clutter',\n",
       "      'and',\n",
       "      \"that's\",\n",
       "      'not',\n",
       "      'me.'],\n",
       "     'metadata': []}],\n",
       "   [{'content': 'Interviewer:\\r', 'tokens': ['Interviewer:'], 'metadata': []}],\n",
       "   [{'content': 'Clutter. Okay.\\r',\n",
       "     'tokens': ['Clutter.', 'Okay.'],\n",
       "     'metadata': []}],\n",
       "   [{'content': 'Participant 1:\\r',\n",
       "     'tokens': ['Participant', '1:'],\n",
       "     'metadata': []}],\n",
       "   [{'content': \"That's not me. I have papers in every room, but I would never have papers so I couldn't get out the door I couldn't ... that's ridiculous. And like things that I have... I have a computer that's old and I want to throw it away but I need to get it right. And it's sitting in my office. It needs to be gotten rid of and I want to get rid of it. It's just I haven't because I don't know where to take it. Sometimes when those things come up, I'm not in the right place at the right time, so those kind of things. But no. I'm not like that. And I'm always usually early or on time, I think. So ...\\r\",\n",
       "     'tokens': [\"That's\",\n",
       "      'not',\n",
       "      'me.',\n",
       "      'I',\n",
       "      'have',\n",
       "      'papers',\n",
       "      'in',\n",
       "      'every',\n",
       "      'room,',\n",
       "      'but',\n",
       "      'I',\n",
       "      'would',\n",
       "      'never',\n",
       "      'have',\n",
       "      'papers',\n",
       "      'so',\n",
       "      'I',\n",
       "      \"couldn't\",\n",
       "      'get',\n",
       "      'out',\n",
       "      'the',\n",
       "      'door',\n",
       "      'I',\n",
       "      \"couldn't\",\n",
       "      '...',\n",
       "      \"that's\",\n",
       "      'ridiculous.',\n",
       "      'And',\n",
       "      'like',\n",
       "      'things',\n",
       "      'that',\n",
       "      'I',\n",
       "      'have...',\n",
       "      'I',\n",
       "      'have',\n",
       "      'a',\n",
       "      'computer',\n",
       "      \"that's\",\n",
       "      'old',\n",
       "      'and',\n",
       "      'I',\n",
       "      'want',\n",
       "      'to',\n",
       "      'throw',\n",
       "      'it',\n",
       "      'away',\n",
       "      'but',\n",
       "      'I',\n",
       "      'need',\n",
       "      'to',\n",
       "      'get',\n",
       "      'it',\n",
       "      'right.',\n",
       "      'And',\n",
       "      \"it's\",\n",
       "      'sitting',\n",
       "      'in',\n",
       "      'my',\n",
       "      'office.',\n",
       "      'It',\n",
       "      'needs',\n",
       "      'to',\n",
       "      'be',\n",
       "      'gotten',\n",
       "      'rid',\n",
       "      'of',\n",
       "      'and',\n",
       "      'I',\n",
       "      'want',\n",
       "      'to',\n",
       "      'get',\n",
       "      'rid',\n",
       "      'of',\n",
       "      'it.',\n",
       "      \"It's\",\n",
       "      'just',\n",
       "      'I',\n",
       "      \"haven't\",\n",
       "      'because',\n",
       "      'I',\n",
       "      \"don't\",\n",
       "      'know',\n",
       "      'where',\n",
       "      'to',\n",
       "      'take',\n",
       "      'it.',\n",
       "      'Sometimes',\n",
       "      'when',\n",
       "      'those',\n",
       "      'things',\n",
       "      'come',\n",
       "      'up,',\n",
       "      \"I'm\",\n",
       "      'not',\n",
       "      'in',\n",
       "      'the',\n",
       "      'right',\n",
       "      'place',\n",
       "      'at',\n",
       "      'the',\n",
       "      'right',\n",
       "      'time,',\n",
       "      'so',\n",
       "      'those',\n",
       "      'kind',\n",
       "      'of',\n",
       "      'things.',\n",
       "      'But',\n",
       "      'no.',\n",
       "      \"I'm\",\n",
       "      'not',\n",
       "      'like',\n",
       "      'that.',\n",
       "      'And',\n",
       "      \"I'm\",\n",
       "      'always',\n",
       "      'usually',\n",
       "      'early',\n",
       "      'or',\n",
       "      'on',\n",
       "      'time,',\n",
       "      'I',\n",
       "      'think.',\n",
       "      'So',\n",
       "      '...'],\n",
       "     'metadata': []}],\n",
       "   [{'content': 'Interviewer:\\r', 'tokens': ['Interviewer:'], 'metadata': []}],\n",
       "   [{'content': 'Perfect. Okay. And do you think this person should try to change their behavior?\\r',\n",
       "     'tokens': ['Perfect.',\n",
       "      'Okay.',\n",
       "      'And',\n",
       "      'do',\n",
       "      'you',\n",
       "      'think',\n",
       "      'this',\n",
       "      'person',\n",
       "      'should',\n",
       "      'try',\n",
       "      'to',\n",
       "      'change',\n",
       "      'their',\n",
       "      'behavior?'],\n",
       "     'metadata': []}],\n",
       "   [{'content': 'Participant 1:\\r',\n",
       "     'tokens': ['Participant', '1:'],\n",
       "     'metadata': []}],\n",
       "   [{'content': 'Yeah.\\r', 'tokens': ['Yeah.'], 'metadata': []}],\n",
       "   [{'content': 'Interviewer:\\r', 'tokens': ['Interviewer:'], 'metadata': []}],\n",
       "   [{'content': 'Okay. And why do you say that?\\r',\n",
       "     'tokens': ['Okay.', 'And', 'why', 'do', 'you', 'say', 'that?'],\n",
       "     'metadata': []}],\n",
       "   [{'content': 'Participant 1:\\r',\n",
       "     'tokens': ['Participant', '1:'],\n",
       "     'metadata': []}],\n",
       "   [{'content': \"Yes. Because he can't get through his house. There's something wrong. My aunt had a neighbor like that and I gave her this gift and she gave it to her neighbor, because her neighbor coveted it, but you go to her neighbor's house and she can barely make a path through the house and their neighbor didn't really ... I got mad she gave it away because this neighbor just wanted it to put in her piles of crap. \\r\",\n",
       "     'tokens': ['Yes.',\n",
       "      'Because',\n",
       "      'he',\n",
       "      \"can't\",\n",
       "      'get',\n",
       "      'through',\n",
       "      'his',\n",
       "      'house.',\n",
       "      \"There's\",\n",
       "      'something',\n",
       "      'wrong.',\n",
       "      'My',\n",
       "      'aunt',\n",
       "      'had',\n",
       "      'a',\n",
       "      'neighbor',\n",
       "      'like',\n",
       "      'that',\n",
       "      'and',\n",
       "      'I',\n",
       "      'gave',\n",
       "      'her',\n",
       "      'this',\n",
       "      'gift',\n",
       "      'and',\n",
       "      'she',\n",
       "      'gave',\n",
       "      'it',\n",
       "      'to',\n",
       "      'her',\n",
       "      'neighbor,',\n",
       "      'because',\n",
       "      'her',\n",
       "      'neighbor',\n",
       "      'coveted',\n",
       "      'it,',\n",
       "      'but',\n",
       "      'you',\n",
       "      'go',\n",
       "      'to',\n",
       "      'her',\n",
       "      \"neighbor's\",\n",
       "      'house',\n",
       "      'and',\n",
       "      'she',\n",
       "      'can',\n",
       "      'barely',\n",
       "      'make',\n",
       "      'a',\n",
       "      'path',\n",
       "      'through',\n",
       "      'the',\n",
       "      'house',\n",
       "      'and',\n",
       "      'their',\n",
       "      'neighbor',\n",
       "      \"didn't\",\n",
       "      'really',\n",
       "      '...',\n",
       "      'I',\n",
       "      'got',\n",
       "      'mad',\n",
       "      'she',\n",
       "      'gave',\n",
       "      'it',\n",
       "      'away',\n",
       "      'because',\n",
       "      'this',\n",
       "      'neighbor',\n",
       "      'just',\n",
       "      'wanted',\n",
       "      'it',\n",
       "      'to',\n",
       "      'put',\n",
       "      'in',\n",
       "      'her',\n",
       "      'piles',\n",
       "      'of',\n",
       "      'crap.'],\n",
       "     'metadata': []}],\n",
       "   [{'content': 'Interviewer:\\r', 'tokens': ['Interviewer:'], 'metadata': []}],\n",
       "   [{'content': 'Of course. Yeah.\\r',\n",
       "     'tokens': ['Of', 'course.', 'Yeah.'],\n",
       "     'metadata': []}],\n",
       "   [{'content': 'Participant 1:\\r',\n",
       "     'tokens': ['Participant', '1:'],\n",
       "     'metadata': []}],\n",
       "   [{'content': \"People that can't get into their house and stuff like that, there's something wrong. Yeah.\\r\",\n",
       "     'tokens': ['People',\n",
       "      'that',\n",
       "      \"can't\",\n",
       "      'get',\n",
       "      'into',\n",
       "      'their',\n",
       "      'house',\n",
       "      'and',\n",
       "      'stuff',\n",
       "      'like',\n",
       "      'that,',\n",
       "      \"there's\",\n",
       "      'something',\n",
       "      'wrong.',\n",
       "      'Yeah.'],\n",
       "     'metadata': []}],\n",
       "   [{'content': 'Interviewer:\\r', 'tokens': ['Interviewer:'], 'metadata': []}],\n",
       "   [{'content': 'Yeah. Definitely. Okay. Perfect. So okay. I have another story for you. Okay. John Doe has clothes that he likes to keep in case he needs to use them in the future. Clothes occupy most of his room except for the kitchen and his bedroom.\\r',\n",
       "     'tokens': ['Yeah.',\n",
       "      'Definitely.',\n",
       "      'Okay.',\n",
       "      'Perfect.',\n",
       "      'So',\n",
       "      'okay.',\n",
       "      'I',\n",
       "      'have',\n",
       "      'another',\n",
       "      'story',\n",
       "      'for',\n",
       "      'you.',\n",
       "      'Okay.',\n",
       "      'John',\n",
       "      'Doe',\n",
       "      'has',\n",
       "      'clothes',\n",
       "      'that',\n",
       "      'he',\n",
       "      'likes',\n",
       "      'to',\n",
       "      'keep',\n",
       "      'in',\n",
       "      'case',\n",
       "      'he',\n",
       "      'needs',\n",
       "      'to',\n",
       "      'use',\n",
       "      'them',\n",
       "      'in',\n",
       "      'the',\n",
       "      'future.',\n",
       "      'Clothes',\n",
       "      'occupy',\n",
       "      'most',\n",
       "      'of',\n",
       "      'his',\n",
       "      'room',\n",
       "      'except',\n",
       "      'for',\n",
       "      'the',\n",
       "      'kitchen',\n",
       "      'and',\n",
       "      'his',\n",
       "      'bedroom.'],\n",
       "     'metadata': []}],\n",
       "   [{'content': 'Participant 1:\\r',\n",
       "     'tokens': ['Participant', '1:'],\n",
       "     'metadata': []}],\n",
       "   [{'content': 'Oh my god.',\n",
       "     'tokens': ['Oh', 'my', 'god.'],\n",
       "     'metadata': []}]],\n",
       "  'labelerInfo': {'id': 7436,\n",
       "   'email': 'smoeller@ufl.edu',\n",
       "   'displayName': 'Sarah Moeller'},\n",
       "  'labelSets': [{'name': 'HD tagset',\n",
       "    'index': 0,\n",
       "    'labelItems': [{'id': 'zynoJJigppWPaLrXIbl7r',\n",
       "      'labelName': 'Incomplete Thought'},\n",
       "     {'id': 'CVVUxC8SvzFkW325Jv13R', 'labelName': 'Self Correction'},\n",
       "     {'id': 'yJ2I5X2l397BXK0vkQOqb', 'labelName': 'Clarification'},\n",
       "     {'id': '-JMh1Z2QiTPafZ-k12D4R', 'labelName': 'Generic Disfluency'},\n",
       "     {'id': 'zNhzFxWreupeViuWpVQbm', 'labelName': 'Misspeak'},\n",
       "     {'id': 'nmDmE8yCiIjn1v0WJrgTj', 'labelName': 'Unclear'},\n",
       "     {'id': '2ioD6do-k6wc54hq7MBd_', 'labelName': 'Overlap'}]}],\n",
       "  'spanLabels': [{'id': '1706871071',\n",
       "    'labeledBy': 'REVIEWER',\n",
       "    'labeledByUserId': 7646,\n",
       "    'acceptedByUserId': None,\n",
       "    'rejectedByUserId': None,\n",
       "    'layer': 0,\n",
       "    'counter': 0,\n",
       "    'status': 'LABELED',\n",
       "    'hashCode': 'SPAN:2ioD6do-k6wc54hq7MBd_:0:1:0:159:0:1:0:162:3:0:undefined:undefined',\n",
       "    'labelName': '2ioD6do-k6wc54hq7MBd_',\n",
       "    'labelItem': {'id': '2ioD6do-k6wc54hq7MBd_', 'labelName': 'Overlap'},\n",
       "    'textPosition': {'start': {'row': 1,\n",
       "      'column': 0,\n",
       "      'tokenIndex': 159,\n",
       "      'charIndex': 0},\n",
       "     'end': {'row': 1, 'column': 0, 'tokenIndex': 162, 'charIndex': 3}},\n",
       "    'confidenceScore': None},\n",
       "   {'id': '1690351611',\n",
       "    'labeledBy': 'REVIEWER',\n",
       "    'labeledByUserId': 7569,\n",
       "    'acceptedByUserId': None,\n",
       "    'rejectedByUserId': None,\n",
       "    'layer': 0,\n",
       "    'counter': 0,\n",
       "    'status': 'LABELED',\n",
       "    'hashCode': 'SPAN:zynoJJigppWPaLrXIbl7r:0:7:0:22:0:7:0:23:7:0:undefined:undefined',\n",
       "    'labelName': 'zynoJJigppWPaLrXIbl7r',\n",
       "    'labelItem': {'id': 'zynoJJigppWPaLrXIbl7r',\n",
       "     'labelName': 'Incomplete Thought'},\n",
       "    'textPosition': {'start': {'row': 7,\n",
       "      'column': 0,\n",
       "      'tokenIndex': 22,\n",
       "      'charIndex': 0},\n",
       "     'end': {'row': 7, 'column': 0, 'tokenIndex': 23, 'charIndex': 7}},\n",
       "    'confidenceScore': None},\n",
       "   {'id': '1690189343',\n",
       "    'labeledBy': 'REVIEWER',\n",
       "    'labeledByUserId': 7569,\n",
       "    'acceptedByUserId': None,\n",
       "    'rejectedByUserId': None,\n",
       "    'layer': 0,\n",
       "    'counter': 0,\n",
       "    'status': 'LABELED',\n",
       "    'hashCode': 'SPAN:-JMh1Z2QiTPafZ-k12D4R:0:7:0:27:0:7:0:32:6:0:undefined:undefined',\n",
       "    'labelName': '-JMh1Z2QiTPafZ-k12D4R',\n",
       "    'labelItem': {'id': '-JMh1Z2QiTPafZ-k12D4R',\n",
       "     'labelName': 'Generic Disfluency'},\n",
       "    'textPosition': {'start': {'row': 7,\n",
       "      'column': 0,\n",
       "      'tokenIndex': 27,\n",
       "      'charIndex': 0},\n",
       "     'end': {'row': 7, 'column': 0, 'tokenIndex': 32, 'charIndex': 6}},\n",
       "    'confidenceScore': None},\n",
       "   {'id': '1706871072',\n",
       "    'labeledBy': 'REVIEWER',\n",
       "    'labeledByUserId': 7646,\n",
       "    'acceptedByUserId': None,\n",
       "    'rejectedByUserId': None,\n",
       "    'layer': 0,\n",
       "    'counter': 0,\n",
       "    'status': 'LABELED',\n",
       "    'hashCode': 'SPAN:2ioD6do-k6wc54hq7MBd_:0:7:0:123:0:7:0:123:1:0:undefined:undefined',\n",
       "    'labelName': '2ioD6do-k6wc54hq7MBd_',\n",
       "    'labelItem': {'id': '2ioD6do-k6wc54hq7MBd_', 'labelName': 'Overlap'},\n",
       "    'textPosition': {'start': {'row': 7,\n",
       "      'column': 0,\n",
       "      'tokenIndex': 123,\n",
       "      'charIndex': 0},\n",
       "     'end': {'row': 7, 'column': 0, 'tokenIndex': 123, 'charIndex': 1}},\n",
       "    'confidenceScore': None},\n",
       "   {'id': '1706707246',\n",
       "    'labeledBy': 'REVIEWER',\n",
       "    'labeledByUserId': 1010,\n",
       "    'acceptedByUserId': None,\n",
       "    'rejectedByUserId': None,\n",
       "    'layer': 0,\n",
       "    'counter': 0,\n",
       "    'status': 'LABELED',\n",
       "    'hashCode': 'SPAN:zynoJJigppWPaLrXIbl7r:0:15:0:54:0:15:0:57:5:0:undefined:undefined',\n",
       "    'labelName': 'zynoJJigppWPaLrXIbl7r',\n",
       "    'labelItem': {'id': 'zynoJJigppWPaLrXIbl7r',\n",
       "     'labelName': 'Incomplete Thought'},\n",
       "    'textPosition': {'start': {'row': 15,\n",
       "      'column': 0,\n",
       "      'tokenIndex': 54,\n",
       "      'charIndex': 0},\n",
       "     'end': {'row': 15, 'column': 0, 'tokenIndex': 57, 'charIndex': 5}},\n",
       "    'confidenceScore': None}],\n",
       "  'arrowLabels': [],\n",
       "  'boundingBoxLabels': [],\n",
       "  'timeLabels': [],\n",
       "  'comments': [],\n",
       "  'url': 'datasaur://static/7436/79613662-16c6-4edd-bc0f-e7f25de6f7a2.txt'}}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(review_dir + test_file) as f:\n",
    "    raw_data = json.load(f)\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['project', 'document', 'kinds', 'rows', 'labelerInfo', 'labelSets', 'spanLabels', 'arrowLabels', 'boundingBoxLabels', 'timeLabels', 'comments', 'url'])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = raw_data['data']\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'id': 'NDE5MzE1ZWM',\n",
       "  'name': 'HD_set1_1-7',\n",
       "  'completedAt': '2025-02-26T00:50:59.000Z'},\n",
       " {'id': 'f50c25c9-451a-4693-aea5-28081dac0250', 'name': '001_006.txt'},\n",
       " ['TOKEN_BASED'])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['project'], data['document'], data['kinds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "INTERVIEWER_NAMES = [\"Interviewer\", \"Rebecca\"]\n",
    "PARTICIPANT_NAMES = [\"Participant\", \"Interviewee\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Interviewer',\n",
       " 'Interviewer',\n",
       " 'Participant',\n",
       " 'Participant',\n",
       " 'Interviewer',\n",
       " 'Interviewer',\n",
       " 'Participant',\n",
       " 'Participant',\n",
       " 'Interviewer',\n",
       " 'Interviewer',\n",
       " 'Participant',\n",
       " 'Participant',\n",
       " 'Interviewer',\n",
       " 'Interviewer',\n",
       " 'Participant',\n",
       " 'Participant',\n",
       " 'Interviewer',\n",
       " 'Interviewer',\n",
       " 'Participant',\n",
       " 'Participant',\n",
       " 'Interviewer',\n",
       " 'Interviewer',\n",
       " 'Participant',\n",
       " 'Participant']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_speakers = [''] * len(data['rows'])\n",
    "speaker = \"\"\n",
    "for i in range(len(data['rows'])):\n",
    "    row = data['rows'][i]\n",
    "    for column in row:\n",
    "        if (column['content'].find(\":\") != -1):\n",
    "            slice_with_potential_speaker: str = column['content'].split(\":\")[0].title()\n",
    "            speaker_found = False\n",
    "            for name in INTERVIEWER_NAMES:\n",
    "                if name in slice_with_potential_speaker:\n",
    "                    speaker = INTERVIEWER_NAMES[0]\n",
    "                    break\n",
    "            # Don't look for participant name if we already found the interviewer\n",
    "            if not speaker_found: \n",
    "                for name in PARTICIPANT_NAMES:\n",
    "                    if name in slice_with_potential_speaker:\n",
    "                        speaker = PARTICIPANT_NAMES[0]\n",
    "                        break\n",
    "        row_speakers[i] = speaker\n",
    "row_speakers\n",
    "# speakers = set([d['speaker'] for row in rows for d in row])\n",
    "# assert len(set([d['speaker'] for row in rows for d in row])) == 2 # make sure there are only two speakers in each row\n",
    "# speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '1706871071',\n",
       "  'labeledBy': 'REVIEWER',\n",
       "  'labeledByUserId': 7646,\n",
       "  'acceptedByUserId': None,\n",
       "  'rejectedByUserId': None,\n",
       "  'layer': 0,\n",
       "  'counter': 0,\n",
       "  'status': 'LABELED',\n",
       "  'hashCode': 'SPAN:2ioD6do-k6wc54hq7MBd_:0:1:0:159:0:1:0:162:3:0:undefined:undefined',\n",
       "  'labelName': '2ioD6do-k6wc54hq7MBd_',\n",
       "  'labelItem': {'id': '2ioD6do-k6wc54hq7MBd_', 'labelName': 'Overlap'},\n",
       "  'textPosition': {'start': {'row': 1,\n",
       "    'column': 0,\n",
       "    'tokenIndex': 159,\n",
       "    'charIndex': 0},\n",
       "   'end': {'row': 1, 'column': 0, 'tokenIndex': 162, 'charIndex': 3}},\n",
       "  'confidenceScore': None},\n",
       " {'id': '1690351611',\n",
       "  'labeledBy': 'REVIEWER',\n",
       "  'labeledByUserId': 7569,\n",
       "  'acceptedByUserId': None,\n",
       "  'rejectedByUserId': None,\n",
       "  'layer': 0,\n",
       "  'counter': 0,\n",
       "  'status': 'LABELED',\n",
       "  'hashCode': 'SPAN:zynoJJigppWPaLrXIbl7r:0:7:0:22:0:7:0:23:7:0:undefined:undefined',\n",
       "  'labelName': 'zynoJJigppWPaLrXIbl7r',\n",
       "  'labelItem': {'id': 'zynoJJigppWPaLrXIbl7r',\n",
       "   'labelName': 'Incomplete Thought'},\n",
       "  'textPosition': {'start': {'row': 7,\n",
       "    'column': 0,\n",
       "    'tokenIndex': 22,\n",
       "    'charIndex': 0},\n",
       "   'end': {'row': 7, 'column': 0, 'tokenIndex': 23, 'charIndex': 7}},\n",
       "  'confidenceScore': None},\n",
       " {'id': '1690189343',\n",
       "  'labeledBy': 'REVIEWER',\n",
       "  'labeledByUserId': 7569,\n",
       "  'acceptedByUserId': None,\n",
       "  'rejectedByUserId': None,\n",
       "  'layer': 0,\n",
       "  'counter': 0,\n",
       "  'status': 'LABELED',\n",
       "  'hashCode': 'SPAN:-JMh1Z2QiTPafZ-k12D4R:0:7:0:27:0:7:0:32:6:0:undefined:undefined',\n",
       "  'labelName': '-JMh1Z2QiTPafZ-k12D4R',\n",
       "  'labelItem': {'id': '-JMh1Z2QiTPafZ-k12D4R',\n",
       "   'labelName': 'Generic Disfluency'},\n",
       "  'textPosition': {'start': {'row': 7,\n",
       "    'column': 0,\n",
       "    'tokenIndex': 27,\n",
       "    'charIndex': 0},\n",
       "   'end': {'row': 7, 'column': 0, 'tokenIndex': 32, 'charIndex': 6}},\n",
       "  'confidenceScore': None},\n",
       " {'id': '1706871072',\n",
       "  'labeledBy': 'REVIEWER',\n",
       "  'labeledByUserId': 7646,\n",
       "  'acceptedByUserId': None,\n",
       "  'rejectedByUserId': None,\n",
       "  'layer': 0,\n",
       "  'counter': 0,\n",
       "  'status': 'LABELED',\n",
       "  'hashCode': 'SPAN:2ioD6do-k6wc54hq7MBd_:0:7:0:123:0:7:0:123:1:0:undefined:undefined',\n",
       "  'labelName': '2ioD6do-k6wc54hq7MBd_',\n",
       "  'labelItem': {'id': '2ioD6do-k6wc54hq7MBd_', 'labelName': 'Overlap'},\n",
       "  'textPosition': {'start': {'row': 7,\n",
       "    'column': 0,\n",
       "    'tokenIndex': 123,\n",
       "    'charIndex': 0},\n",
       "   'end': {'row': 7, 'column': 0, 'tokenIndex': 123, 'charIndex': 1}},\n",
       "  'confidenceScore': None},\n",
       " {'id': '1706707246',\n",
       "  'labeledBy': 'REVIEWER',\n",
       "  'labeledByUserId': 1010,\n",
       "  'acceptedByUserId': None,\n",
       "  'rejectedByUserId': None,\n",
       "  'layer': 0,\n",
       "  'counter': 0,\n",
       "  'status': 'LABELED',\n",
       "  'hashCode': 'SPAN:zynoJJigppWPaLrXIbl7r:0:15:0:54:0:15:0:57:5:0:undefined:undefined',\n",
       "  'labelName': 'zynoJJigppWPaLrXIbl7r',\n",
       "  'labelItem': {'id': 'zynoJJigppWPaLrXIbl7r',\n",
       "   'labelName': 'Incomplete Thought'},\n",
       "  'textPosition': {'start': {'row': 15,\n",
       "    'column': 0,\n",
       "    'tokenIndex': 54,\n",
       "    'charIndex': 0},\n",
       "   'end': {'row': 15, 'column': 0, 'tokenIndex': 57, 'charIndex': 5}},\n",
       "  'confidenceScore': None}]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is where the meat is at\n",
    "label_data = data['spanLabels']\n",
    "label_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Overlap', 'Interviewer'),\n",
       " ('Incomplete Thought', 'Participant'),\n",
       " ('Generic Disfluency', 'Participant'),\n",
       " ('Overlap', 'Participant'),\n",
       " ('Incomplete Thought', 'Participant')]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_with_speakers = [('', False)] * len(label_data)\n",
    "for i in range(len(label_data)):\n",
    "    label = label_data[i]\n",
    "\n",
    "    row_index = label['textPosition']['start']['row']\n",
    "    speaker = row_speakers[row_index]\n",
    "    labels_with_speakers[i] = (label['labelItem']['labelName'], speaker)\n",
    "labels_with_speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({('Incomplete Thought', 'Participant'): 2,\n",
       "         ('Overlap', 'Interviewer'): 1,\n",
       "         ('Generic Disfluency', 'Participant'): 1,\n",
       "         ('Overlap', 'Participant'): 1,\n",
       "         ('Clarification', 'Interviewer'): 0,\n",
       "         ('Clarification', 'Participant'): 0,\n",
       "         ('Incomplete Thought', 'Interviewer'): 0,\n",
       "         ('Misspeak', 'Interviewer'): 0,\n",
       "         ('Misspeak', 'Participant'): 0,\n",
       "         ('Generic Disfluency', 'Interviewer'): 0,\n",
       "         ('Self Correction', 'Interviewer'): 0,\n",
       "         ('Unclear', 'Interviewer'): 0,\n",
       "         ('Self Correction', 'Participant'): 0,\n",
       "         ('Unclear', 'Participant'): 0})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from itertools import product\n",
    "\n",
    "cntDict = Counter(labels_with_speakers)\n",
    "for label, speaker in set(product(LABELS, ['Interviewer', 'Participant'])).difference(cntDict.keys()):\n",
    "    cntDict[(label, speaker)] = 0\n",
    "cntDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Misspeak–Interviewer': 0,\n",
       " 'Misspeak–Participant': 0,\n",
       " 'Misspeak–Total': 0,\n",
       " 'Unclear–Interviewer': 0,\n",
       " 'Unclear–Participant': 0,\n",
       " 'Unclear–Total': 0,\n",
       " 'Self Correction–Interviewer': 0,\n",
       " 'Self Correction–Participant': 0,\n",
       " 'Self Correction–Total': 0,\n",
       " 'Overlap–Interviewer': 1,\n",
       " 'Overlap–Participant': 1,\n",
       " 'Overlap–Total': 2,\n",
       " 'Clarification–Interviewer': 0,\n",
       " 'Clarification–Participant': 0,\n",
       " 'Clarification–Total': 0,\n",
       " 'Generic Disfluency–Interviewer': 0,\n",
       " 'Generic Disfluency–Participant': 1,\n",
       " 'Generic Disfluency–Total': 1,\n",
       " 'Incomplete Thought–Interviewer': 0,\n",
       " 'Incomplete Thought–Participant': 2,\n",
       " 'Incomplete Thought–Total': 2,\n",
       " 'Total': 5}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display_dict = {}\n",
    "for label in LABELS:\n",
    "    display_dict[label+'–Interviewer'] = cntDict[(label, 'Interviewer')]\n",
    "    display_dict[label+'–Participant'] = cntDict[(label, 'Participant')]\n",
    "    display_dict[label+'–Total'] = cntDict[(label, 'Interviewer')] + cntDict[(label, 'Participant')]\n",
    "display_dict['Total'] = sum(cntDict.values())\n",
    "display_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5051124744376279"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert not [row for row in data['rows'] if len(row) != 1] # make sure each row is a singleton list\n",
    "doc_tokens = [row[0]['tokens'] for row in data['rows']]\n",
    "flat_doc_tokens = [token for row in doc_tokens for token in row]\n",
    "len(set(flat_doc_tokens)) / len(flat_doc_tokens) # TTR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.375"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = 0\n",
    "for sent in doc_tokens:\n",
    "    words += len(sent)\n",
    "words / len(doc_tokens) # average sentence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'filename': '001_006.txt',\n",
       " 'isHoarder': 1,\n",
       " 'Misspeak–Interviewer': 0,\n",
       " 'Misspeak–Participant': 0,\n",
       " 'Misspeak–Total': 0,\n",
       " 'Unclear–Interviewer': 0,\n",
       " 'Unclear–Participant': 0,\n",
       " 'Unclear–Total': 0,\n",
       " 'Self Correction–Interviewer': 0,\n",
       " 'Self Correction–Participant': 0,\n",
       " 'Self Correction–Total': 0,\n",
       " 'Overlap–Interviewer': 1,\n",
       " 'Overlap–Participant': 1,\n",
       " 'Overlap–Total': 2,\n",
       " 'Clarification–Interviewer': 0,\n",
       " 'Clarification–Participant': 0,\n",
       " 'Clarification–Total': 0,\n",
       " 'Generic Disfluency–Interviewer': 0,\n",
       " 'Generic Disfluency–Participant': 1,\n",
       " 'Generic Disfluency–Total': 1,\n",
       " 'Incomplete Thought–Interviewer': 0,\n",
       " 'Incomplete Thought–Participant': 2,\n",
       " 'Incomplete Thought–Total': 2,\n",
       " 'Total': 5}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row = {\n",
    "    'filename' : data['document']['name'], ''\n",
    "    'isHoarder' : hoarder_flag, \n",
    "    **display_dict\n",
    "}\n",
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "filename",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "isHoarder",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Incomplete Thought - Interviewer",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Incomplete Thought - Participant",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Incomplete Thought - Total",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Clarification - Interviewer",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Clarification - Participant",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Clarification - Total",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Generic Disfluency - Interviewer",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Generic Disfluency - Participant",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Generic Disfluency - Total",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Overlap - Interviewer",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Overlap - Participant",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Overlap - Total",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Unclear - Interviewer",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Unclear - Participant",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Unclear - Total",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Misspeak - Interviewer",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Misspeak - Participant",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Misspeak - Total",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Self Correction - Interviewer",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Self Correction - Participant",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Self Correction - Total",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Total",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "ecc953b2-27e9-45e8-9795-24b45bd47cd5",
       "rows": [
        [
         "0",
         "2013_211.txt",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "1",
         "1",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "1"
        ]
       ],
       "shape": {
        "columns": 24,
        "rows": 1
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>isHoarder</th>\n",
       "      <th>Incomplete Thought - Interviewer</th>\n",
       "      <th>Incomplete Thought - Participant</th>\n",
       "      <th>Incomplete Thought - Total</th>\n",
       "      <th>Clarification - Interviewer</th>\n",
       "      <th>Clarification - Participant</th>\n",
       "      <th>Clarification - Total</th>\n",
       "      <th>Generic Disfluency - Interviewer</th>\n",
       "      <th>Generic Disfluency - Participant</th>\n",
       "      <th>...</th>\n",
       "      <th>Unclear - Interviewer</th>\n",
       "      <th>Unclear - Participant</th>\n",
       "      <th>Unclear - Total</th>\n",
       "      <th>Misspeak - Interviewer</th>\n",
       "      <th>Misspeak - Participant</th>\n",
       "      <th>Misspeak - Total</th>\n",
       "      <th>Self Correction - Interviewer</th>\n",
       "      <th>Self Correction - Participant</th>\n",
       "      <th>Self Correction - Total</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013_211.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       filename  isHoarder  Incomplete Thought - Interviewer  \\\n",
       "0  2013_211.txt          0                                 0   \n",
       "\n",
       "   Incomplete Thought - Participant  Incomplete Thought - Total  \\\n",
       "0                                 0                           0   \n",
       "\n",
       "   Clarification - Interviewer  Clarification - Participant  \\\n",
       "0                            0                            0   \n",
       "\n",
       "   Clarification - Total  Generic Disfluency - Interviewer  \\\n",
       "0                      0                                 0   \n",
       "\n",
       "   Generic Disfluency - Participant  ...  Unclear - Interviewer  \\\n",
       "0                                 1  ...                      0   \n",
       "\n",
       "   Unclear - Participant  Unclear - Total  Misspeak - Interviewer  \\\n",
       "0                      0                0                       0   \n",
       "\n",
       "   Misspeak - Participant  Misspeak - Total  Self Correction - Interviewer  \\\n",
       "0                       0                 0                              0   \n",
       "\n",
       "   Self Correction - Participant  Self Correction - Total  Total  \n",
       "0                              0                        0      1  \n",
       "\n",
       "[1 rows x 24 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame([row])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
