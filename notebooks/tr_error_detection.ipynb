{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42bf09be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Input folder: /Users/admin/Documents/coding_land/HoardingDisorderScripts/data/s1055-1058/REVIEW\n",
      "[INFO] Found 37 files matching *.txt.json\n",
      "[INFO] After filtering by stem '055_684': 1 file(s)\n",
      "\n",
      "======================================================================\n",
      "[FILE] 055_684.txt.json\n",
      "All Named Entities (NER):\n",
      "26:28                          -> CARDINAL\n",
      "26:42                          -> CARDINAL\n",
      "26:48                          -> CARDINAL\n",
      "I’ve                           -> PERSON\n",
      "27:01                          -> CARDINAL\n",
      "27:07                          -> CARDINAL\n",
      "Gotcha                         -> PERSON\n",
      "two                            -> CARDINAL\n",
      "27:33                          -> CARDINAL\n",
      "27:38                          -> CARDINAL\n",
      "27:41                          -> CARDINAL\n",
      "28:09                          -> CARDINAL\n",
      "28:18                          -> CARDINAL\n",
      "Gotcha                         -> PERSON\n",
      "28:42                          -> CARDINAL\n",
      "29:04                          -> CARDINAL\n",
      "29:12                          -> CARDINAL\n",
      "29:18                          -> CARDINAL\n",
      "Gotcha                         -> PERSON\n",
      "29:55                          -> CARDINAL\n",
      "30:02                          -> CARDINAL\n",
      "30:12                          -> CARDINAL\n",
      "Mhmm                           -> PERSON\n",
      "30:26                          -> CARDINAL\n",
      "\n",
      "PERSON entities:\n",
      "I’ve\n",
      "Gotcha\n",
      "Gotcha\n",
      "Gotcha\n",
      "Mhmm\n",
      "\n",
      "Title + Name pairs (POS-based):\n",
      "(none)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import stanza\n",
    "import re\n",
    "from difflib import get_close_matches\n",
    "import sys \n",
    "\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "from utils.regexes import SPEAKER_PAIRS, SPEAKERS, speaker_labels, speaker_labels_restricted\n",
    "\n",
    "nlp = stanza.Pipeline(lang=\"en\", processors=\"tokenize,mwt,pos,lemma,ner\", verbose=False)\n",
    "\n",
    "def detect_proper_nouns(text: str, nlp_pipeline, include_non_person: bool = False, show_title_pairs: bool = True):\n",
    "    doc = nlp_pipeline(text)\n",
    "    # show all NER entities\n",
    "    if include_non_person:\n",
    "        print(\"All Named Entities (NER):\")\n",
    "        for ent in doc.ents:\n",
    "            print(f\"{ent.text:<30} -> {ent.type}\")\n",
    "\n",
    "    # PERSON-only view\n",
    "    print(\"\\nPERSON entities:\")\n",
    "    person_tags = {\"PERSON\", \"PER\"}\n",
    "    found_person = False\n",
    "    for ent in doc.ents:\n",
    "        if ent.type in person_tags:\n",
    "            found_person = True\n",
    "            print(ent.text)\n",
    "    if not found_person:\n",
    "        print(\"(none)\")\n",
    "\n",
    "    # Lightweight title + name using POS\n",
    "    if show_title_pairs:\n",
    "        print(\"\\nTitle + Name pairs (POS-based):\")\n",
    "        title_words = {\"Dr.\", \"Mr.\", \"Ms.\", \"Miss.\", \"Mrs.\", \"Prof.\", \"Professor\"}\n",
    "        found_pair = False\n",
    "        for sent in doc.sentences:\n",
    "            words = sent.words\n",
    "            for i in range(len(words) - 1):\n",
    "                if words[i].text in title_words and words[i + 1].upos == \"PROPN\":\n",
    "                    found_pair = True\n",
    "                    print(f\"{words[i].text} {words[i+1].text}\")\n",
    "        if not found_pair:\n",
    "            print(\"(none)\")\n",
    "\n",
    "def process_transcripts(input_folder, nlp_pipeline, only_stem: str | None = None,\n",
    "                        include_non_person: bool = False, show_title_pairs: bool = True):\n",
    "    input_path = Path(input_folder).resolve()\n",
    "    print(f\"[INFO] Input folder: {input_path}\")\n",
    "    files = sorted(input_path.glob(\"*.txt.json\"))\n",
    "    print(f\"[INFO] Found {len(files)} files matching *.txt.json\")\n",
    "    if only_stem:\n",
    "        files = [f for f in files if f.stem.startswith(only_stem)]\n",
    "        print(f\"[INFO] After filtering by stem '{only_stem}': {len(files)} file(s)\")\n",
    "\n",
    "    if not files:\n",
    "        print(\"[WARN] No matching files.\")\n",
    "        return\n",
    "\n",
    "    for file in files:\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(f\"[FILE] {file.name}\")\n",
    "        with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        rows = data.get(\"rows\", [])\n",
    "        if not rows:\n",
    "            print(\"[WARN] Skipping: No 'rows' key or it's empty.\")\n",
    "            continue\n",
    "\n",
    "        text = \"\\n\".join(row.get(\"content\", \"\") for row in rows)\n",
    "        detect_proper_nouns(text, nlp_pipeline, include_non_person=include_non_person, show_title_pairs=show_title_pairs)\n",
    "\n",
    "def process_string(sample_text: str, nlp_pipeline, include_non_person: bool = True, show_title_pairs: bool = True):\n",
    "    print(\"[INFO] Running detection on a literal string…\")\n",
    "    detect_proper_nouns(sample_text, nlp_pipeline, include_non_person=include_non_person, show_title_pairs=show_title_pairs)\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    # Example: adjust to your project layout\n",
    "    project_root = Path.cwd().parent\n",
    "    input_folder = project_root / \"data\" / \"s1055-1058\" / \"REVIEW\"\n",
    "\n",
    "    # Target just one file (two test files. in use are 057_707 and 055_684)\n",
    "    process_transcripts(\n",
    "        input_folder=input_folder,\n",
    "        nlp_pipeline=nlp,\n",
    "        only_stem=\"055_684\",          # set to None to scan all\n",
    "        include_non_person=True,       # set False to show only PERSON entities\n",
    "        show_title_pairs=True\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7cfed999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[FILE] 057_707.txt.json\n",
      "NO ERRORS\n",
      "\n",
      "[FILE] 055_678.txt.json\n",
      "YES — errors found: 1\n",
      "  • Bad punctuation after label: 1\n",
      "      line 6: 'Participant 055 (0:33)'\n",
      "\n",
      "[FILE] 055_679.txt.json\n",
      "NO ERRORS\n",
      "\n",
      "[FILE] 055_680.txt.json\n",
      "NO ERRORS\n",
      "\n",
      "[FILE] 055_681.txt.json\n",
      "NO ERRORS\n",
      "\n",
      "[FILE] 055_682.txt.json\n",
      "NO ERRORS\n",
      "\n",
      "[FILE] 055_683.txt.json\n",
      "NO ERRORS\n",
      "\n",
      "[FILE] 055_684.txt.json\n",
      "NO ERRORS\n",
      "\n",
      "[FILE] 055_685.txt.json\n",
      "NO ERRORS\n",
      "\n",
      "[FILE] 055_686.txt.json\n",
      "YES — errors found: 1\n",
      "  • Bad punctuation after label: 1\n",
      "      line 20: 'Participant 055 (36:06)'\n",
      "\n",
      "[FILE] 055_687.txt.json\n",
      "NO ERRORS\n",
      "\n",
      "[FILE] 055_688.txt.json\n",
      "NO ERRORS\n",
      "\n",
      "[FILE] 055_689.txt.json\n",
      "NO ERRORS\n",
      "\n",
      "[FILE] 056_690.txt.json\n",
      "NO ERRORS\n",
      "\n",
      "[FILE] 056_691.txt.json\n",
      "NO ERRORS\n",
      "\n",
      "[FILE] 056_692.txt.json\n",
      "NO ERRORS\n",
      "\n",
      "[FILE] 056_693.txt.json\n",
      "NO ERRORS\n",
      "\n",
      "[FILE] 056_694.txt.json\n",
      "NO ERRORS\n",
      "\n",
      "[FILE] 056_695.txt.json\n",
      "YES — errors found: 1\n",
      "  • Bad punctuation after label: 1\n",
      "      line 10: 'Participant 056 (2:47)'\n",
      "\n",
      "[FILE] 056_696.txt.json\n",
      "NO ERRORS\n",
      "\n",
      "[FILE] 056_697.txt.json\n",
      "YES — errors found: 1\n",
      "  • Bad punctuation after label: 1\n",
      "      line 25: 'Participant 056 (37:40)'\n",
      "\n",
      "[FILE] 056_698.txt.json\n",
      "NO ERRORS\n",
      "\n",
      "[FILE] 056_699.txt.json\n",
      "NO ERRORS\n",
      "\n",
      "[FILE] 056_700.txt.json\n",
      "NO ERRORS\n",
      "\n",
      "[FILE] 057_702.txt.json\n",
      "NO ERRORS\n",
      "\n",
      "[FILE] 057_703.txt.json\n",
      "NO ERRORS\n",
      "\n",
      "[FILE] 057_704.txt.json\n",
      "NO ERRORS\n",
      "\n",
      "[FILE] 057_705.txt.json\n",
      "NO ERRORS\n",
      "\n",
      "[FILE] 057_706.txt.json\n",
      "NO ERRORS\n",
      "\n",
      "[FILE] 057_707.txt.json\n",
      "NO ERRORS\n",
      "\n",
      "[FILE] 058_708.txt.json\n",
      "YES — errors found: 2\n",
      "  • Bad punctuation after label: 2\n",
      "      line 28: 'Participant 058 09:17'\n",
      "      line 32: 'Participant 058 09:27-'\n",
      "\n",
      "[FILE] 058_709.txt.json\n",
      "NO ERRORS\n",
      "\n",
      "[FILE] 058_710.txt.json\n",
      "NO ERRORS\n",
      "\n",
      "[FILE] 058_711.txt.json\n",
      "NO ERRORS\n",
      "\n",
      "[FILE] 058_712.txt.json\n",
      "YES — errors found: 2\n",
      "  • Bad punctuation after label: 2\n",
      "      line 26: 'Participant 058 22:21'\n",
      "      line 54: 'Participant 058 24:22'\n",
      "\n",
      "[FILE] 058_713.txt.json\n",
      "NO ERRORS\n",
      "\n",
      "[FILE] 058_714.txt.json\n",
      "YES — errors found: 4\n",
      "  • Bad punctuation after label: 3\n",
      "      line 19: 'Interviewer 28:51Okay. And why would you'\n",
      "      line 44: 'Participant 058'\n",
      "      line 48: 'Participant 058 29:41'\n",
      "  • Likely misspellings: 1\n",
      "      'Interviewer 28' -> 'Interviewer'\n",
      "\n",
      "[FILE] 058_715.txt.json\n",
      "YES — errors found: 2\n",
      "  • Bad punctuation after label: 1\n",
      "      line 9: 'Interviewer 31:29= And then your email a'\n",
      "  • Likely misspellings: 1\n",
      "      'Interviewer 31' -> 'Interviewer'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import re\n",
    "from difflib import get_close_matches\n",
    "\n",
    "# ---------- Canonical speaker set (fallback if import fails) ----------\n",
    "try:\n",
    "    speaker_set = set(SPEAKERS)  # e.g., from utils.regexes\n",
    "except NameError:\n",
    "    speaker_set = {\"Interviewer\", \"Participant\", \"Interviewee\", \"Speaker\"}\n",
    "\n",
    "# ---------- Helpers ----------\n",
    "def _alt(speakers: set[str]) -> str:\n",
    "    return \"|\".join(re.escape(s) for s in sorted(speakers, key=len, reverse=True))\n",
    "\n",
    "def _iter_lines(text: str):\n",
    "    for i, line in enumerate(text.splitlines(), start=1):\n",
    "        yield i, line\n",
    "\n",
    "# ---------- Producer 1 ----------\n",
    "def find_speaker_format_issues(text: str, speakers: set[str]):\n",
    "    \"\"\"\n",
    "    Returns a dict with two keys; each value is a list of EXACT (line_no, snippet, full_line) tuples:\n",
    "      {\n",
    "        \"spacing_issue\":   [(ln, snip, full), ...],  # there is a space right before the colon\n",
    "        \"bad_punctuation\": [(ln, snip, full), ...],  # label not followed by allowed patterns\n",
    "      }\n",
    "\n",
    "    Allowed patterns after the label:\n",
    "      - optional whitespace + ':'                        -> \"Interviewer: ...\"\n",
    "      - optional whitespace + '(' timestamp ')' + ':'    -> \"Interviewer (20:14): ...\" or \"Interviewer (1:02:33): ...\"\n",
    "    \"\"\"\n",
    "    labels = _alt(speakers)\n",
    "\n",
    "    # Timestamp patterns like (20:14) or (1:02:33), with optional spaces inside\n",
    "    ts = r\"\\(\\s*\\d{1,2}:\\d{2}(?::\\d{2})?\\s*\\)\"\n",
    "\n",
    "    # A fully valid prefix (no error) is:\n",
    "    #   Label [spaces] [optional (timestamp)] [spaces] ':'\n",
    "    valid_prefix = re.compile(\n",
    "        rf\"^\\s*(?:{labels})\\s*(?:{ts})?\\s*:\",\n",
    "        re.MULTILINE\n",
    "    )\n",
    "\n",
    "    # Spacing issue = space(s) immediately before the colon.\n",
    "    # We catch both:\n",
    "    #   - Label [spaces] ':'   (classic)  e.g., \"Interviewer :\"\n",
    "    #   - Label [spaces] (ts) [spaces] ':'  e.g., \"Interviewer (20:14) :\"\n",
    "    spacing_after_label = re.compile(\n",
    "        rf\"^\\s*(?:{labels})\\s+:(?=\\s|\\S)\",\n",
    "        re.MULTILINE\n",
    "    )\n",
    "    spacing_after_label_ts = re.compile(\n",
    "        rf\"^\\s*(?:{labels})\\s*(?:{ts})\\s+:(?=\\s|\\S)\",\n",
    "        re.MULTILINE\n",
    "    )\n",
    "\n",
    "    spacing_hits: list[tuple[int, str, str]] = []\n",
    "    bad_punct_hits: list[tuple[int, str, str]] = []\n",
    "\n",
    "    for ln, line in _iter_lines(text):\n",
    "        # spacing issues (either directly after label, or after timestamp)\n",
    "        if spacing_after_label.search(line) or spacing_after_label_ts.search(line):\n",
    "            snippet = line.strip()[:40]\n",
    "            spacing_hits.append((ln, snippet, line))\n",
    "            # Note: a line can have spacing issue but still be otherwise \"valid\";\n",
    "            # we don't mark it as bad_punctuation if it matches valid_prefix.\n",
    "            continue\n",
    "\n",
    "        # If line begins with a label but does NOT match a valid prefix,\n",
    "        # then it's bad punctuation (e.g., \"Interviewer.\" \"Speaker-\" \"Participant's\" \"Interviewee?\")\n",
    "        starts_with_label = re.match(rf\"^\\s*(?:{labels})\\b\", line)\n",
    "        if starts_with_label and not valid_prefix.search(line):\n",
    "            snippet = line.strip()[:40]\n",
    "            bad_punct_hits.append((ln, snippet, line))\n",
    "\n",
    "    return {\n",
    "        \"spacing_issue\": spacing_hits,\n",
    "        \"bad_punctuation\": bad_punct_hits,\n",
    "    }\n",
    "\n",
    "\n",
    "# ---------- Producer 2 ----------\n",
    "def find_spelling_variants(text: str, speakers: set[str], threshold: float = 0.8):\n",
    "    cand_re = re.compile(r'^([A-Z][A-Za-z0-9_ ]{1,30})(?=\\s*:\\s*)', re.MULTILINE)\n",
    "    candidates = {m.group(1) for m in cand_re.finditer(text)} - speakers\n",
    "    out = {}\n",
    "    for cand in candidates:\n",
    "        match = get_close_matches(cand, list(speakers), n=1, cutoff=threshold)\n",
    "        if match and match[0] != cand:\n",
    "            out[cand] = match[0]\n",
    "    return out\n",
    "\n",
    "# ---------- Producer 3 ----------\n",
    "def find_multi_speaker_lines(text: str, speakers: set[str]):\n",
    "    labels = _alt(speakers)\n",
    "    label_colon = re.compile(rf'\\b({labels})\\s*:', re.IGNORECASE)\n",
    "    hits = []\n",
    "    for ln, line in _iter_lines(text):\n",
    "        found = [m.group(1) for m in label_colon.finditer(line)]\n",
    "        if len(found) >= 2:\n",
    "            hits.append((ln, line, found))\n",
    "    return hits\n",
    "\n",
    "# ---------- Main runner ----------\n",
    "def process_file(file_path: Path):\n",
    "    print(f\"\\n[FILE] {file_path.name}\")\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    rows = data.get(\"rows\", [])\n",
    "    if not rows:\n",
    "        print(\"[WARN] Skipping: No 'rows' key or empty\")\n",
    "        return\n",
    "\n",
    "    text = \"\\n\".join(row.get(\"content\", \"\") for row in rows)\n",
    "\n",
    "    # Run detectors\n",
    "    fmt_issues = find_speaker_format_issues(text, speaker_set)\n",
    "    misspellings = find_spelling_variants(text, speaker_set, threshold=0.8)\n",
    "    multi_lines = find_multi_speaker_lines(text, speaker_set)\n",
    "\n",
    "    total = sum(len(v) for v in fmt_issues.values()) + len(misspellings) + len(multi_lines)\n",
    "\n",
    "    if total:\n",
    "        print(f\"YES — errors found: {total}\")\n",
    "        if fmt_issues[\"spacing_issue\"]:\n",
    "            print(f\"  • Space-before-colon: {len(fmt_issues['spacing_issue'])}\")\n",
    "            for ln, snip, full in fmt_issues[\"spacing_issue\"]:\n",
    "                print(f\"      line {ln}: {snip!r}\")\n",
    "        if fmt_issues[\"bad_punctuation\"]:\n",
    "            print(f\"  • Bad punctuation after label: {len(fmt_issues['bad_punctuation'])}\")\n",
    "            for ln, snip, full in fmt_issues[\"bad_punctuation\"]:\n",
    "                print(f\"      line {ln}: {snip!r}\")\n",
    "        if misspellings:\n",
    "            print(f\"  • Likely misspellings: {len(misspellings)}\")\n",
    "            for bad, sug in misspellings.items():\n",
    "                print(f\"      {bad!r} -> {sug!r}\")\n",
    "        if multi_lines:\n",
    "            print(f\"  • Multiple labels on one line: {len(multi_lines)}\")\n",
    "            for ln, line_txt, labels in multi_lines:\n",
    "                print(f\"      line {ln}: labels={labels} | {line_txt[:120]}\")\n",
    "    else:\n",
    "        print(\"NO ERRORS\")\n",
    "\n",
    "# ---------- Example call ----------\n",
    "if __name__ == \"__main__\":\n",
    "    project_root = Path.cwd().parent  # adjust if needed\n",
    "    input_folder = project_root / \"data\" / \"s1055-1058\" / \"REVIEW\"\n",
    "    target_file = input_folder / \"057_707.txt.json\"   # change this file name\n",
    "\n",
    "    process_file(target_file)\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "def process_all_files(folder_path):\n",
    "    folder = Path(folder_path)\n",
    "    for file in sorted(folder.glob(\"*.txt.json\")):\n",
    "        process_file(file)   # reuse your existing function\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    input_folder = Path.cwd().parent / \"data\" / \"s1055-1058\" / \"REVIEW\"\n",
    "    process_all_files(input_folder)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
